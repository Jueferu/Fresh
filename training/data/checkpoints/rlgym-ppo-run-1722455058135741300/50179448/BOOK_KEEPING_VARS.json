{
    "cumulative_timesteps": 50179448,
    "cumulative_model_updates": 6000,
    "policy_average_reward": 1255.3678596870864,
    "epoch": 999,
    "ts_since_last_save": 50044,
    "reward_running_stats": {
        "mean": [
            30.0870202730787
        ],
        "var": [
            281894578.0330166
        ],
        "shape": [
            1
        ],
        "count": 150450
    }
}