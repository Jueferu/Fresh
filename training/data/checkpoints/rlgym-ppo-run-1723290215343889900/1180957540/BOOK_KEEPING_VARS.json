{
    "cumulative_timesteps": 1180957540,
    "cumulative_model_updates": 93044,
    "policy_average_reward": 41408.49346217948,
    "epoch": 12066,
    "ts_since_last_save": 600030,
    "reward_running_stats": {
        "mean": [
            3259.856557713693
        ],
        "var": [
            3.85661452480569e+16
        ],
        "shape": [
            1
        ],
        "count": 1811850
    }
}