{
    "cumulative_timesteps": 469786996,
    "cumulative_model_updates": 29000,
    "policy_average_reward": 1249.7013897923212,
    "epoch": 4920,
    "ts_since_last_save": 200044,
    "reward_running_stats": {
        "mean": [
            36.218912800415694
        ],
        "var": [
            1077888982.572082
        ],
        "shape": [
            1
        ],
        "count": 739200
    }
}